{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "The data set you will be using is from the UCI Machine Learning DataSet repository.  \n",
    "http://mlr.cs.umass.edu/ml/datasets/Balance+Scale\n",
    "The data set came in two parts: The data and descriptions.  I added the feature names to the front of the data file to make it readable as a CSV file.  You can see all three files in the project directory.\n",
    "\n",
    "It is a Balance scale weight & distance database.  You have a left weight and distance and a right weight and distance.  There are three categories:\n",
    "* B is balanced\n",
    "* L is scale tips left\n",
    "* R is scale tips right\n",
    "\n",
    "There is a simple computation that you can do to determine the category based on the features:  Compute left weight*distance and right weight * distance.  If the left product is greater, then we have a tip left, equal is balanced, right greater is tip right.\n",
    "\n",
    "This data set exhaustively gives examples for all 625 posible combinations of weights of 1, 2, 3, 4, 5 with distances of 1, 2, 3, 4, 5.\n",
    "\n",
    "If generating new instances, we should restrict the weight and distance to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Get the DataSet\n",
    "Read balance-scale.csv into a data frame and use head to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L    288\n",
       "R    288\n",
       "B     49\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"balance-scale.csv\")\n",
    "data.head(n = 10)\n",
    "data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Add two new features Left-Product and Right-Product\n",
    "Compute Left-Weight times Left-Distance and add it as a feature (Left-Product). Do the same for the right.  Look at the data and verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Left-Weight</th>\n",
       "      <th>Left-Distance</th>\n",
       "      <th>Right-Weight</th>\n",
       "      <th>Right-Distance</th>\n",
       "      <th>Left-Product</th>\n",
       "      <th>Right-Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class  Left-Weight  Left-Distance  Right-Weight  Right-Distance  \\\n",
       "0     B            1              1             1               1   \n",
       "1     R            1              1             1               2   \n",
       "2     R            1              1             1               3   \n",
       "3     R            1              1             1               4   \n",
       "4     R            1              1             1               5   \n",
       "\n",
       "   Left-Product  Right-Product  \n",
       "0             1              1  \n",
       "1             1              2  \n",
       "2             1              3  \n",
       "3             1              4  \n",
       "4             1              5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Left-Product\"] = data[\"Left-Weight\"]*data[\"Left-Distance\"]\n",
    "data[\"Right-Product\"] = data[\"Right-Weight\"]*data[\"Right-Distance\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Partition and Plot\n",
    "Partition the data frame by class and then do a scatter plot of the Left-Product vs. the Right-Product with each of the classes in a different color.  Label the axis and create a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lOnesRight= np.ma.masked_where(data[\"Class\"] != \"L\",data[\"Right-Product\"])\n",
    "lOnesLeft= np.ma.masked_where(data[\"Class\"] != \"L\",data[\"Left-Product\"])\n",
    "rOnesRight= np.ma.masked_where(data[\"Class\"] != \"R\",data[\"Right-Product\"])\n",
    "rOnesLeft= np.ma.masked_where(data[\"Class\"] != \"R\",data[\"Left-Product\"])\n",
    "bOnesRight= np.ma.masked_where(data[\"Class\"] != \"B\",data[\"Right-Product\"])\n",
    "bOnesLeft= np.ma.masked_where(data[\"Class\"] != \"B\",data[\"Left-Product\"])\n",
    "\n",
    "ll=plt.scatter(x=lOnesLeft,y=lOnesRight,color = \"green\")\n",
    "rr=plt.scatter(x=rOnesLeft,y=rOnesRight,color = \"red\")\n",
    "bb=plt.scatter(x=bOnesLeft,y=bOnesRight,color = \"blue\")\n",
    "plt.legend((ll,rr,bb),(\"left\",\"right\",\"balanced\"))\n",
    "plt.xlabel(\"Left-Product\")\n",
    "plt.ylabel(\"Right-Product\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Building the decision tree\n",
    "Train a decision tree using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#gonna map class to an int i guess\n",
    "def intClassFn(string1):\n",
    "    if string1 == \"L\":\n",
    "        return int(0)\n",
    "    if string1 == \"B\":\n",
    "        return int(1)\n",
    "    if string1 == \"R\":\n",
    "        return int(2)\n",
    "data[\"intClass\"] = data[\"Class\"].map(intClassFn)\n",
    "y = data[\"intClass\"]\n",
    "x= data[[\"Left-Weight\",\"Left-Distance\",\"Right-Weight\",\"Right-Distance\"]]\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Evaluation  (Confusion Matrix)\n",
    "Create and display the confusion matrix for the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[288   0   0]\n",
      " [  0  49   0]\n",
      " [  0   0 288]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_predicted = tree_classifier.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Evaluation (Other metrics)\n",
    "Compute Accuracy, Precision, Sensitivity and F1 scores from the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is :  1.0\n",
      "the precision is :  1.0\n",
      "the sensitivity is :  1.0\n",
      "the f1 is :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"the accuracy is : \",accuracy_score(y,y_predicted))\n",
    "print(\"the precision is : \",precision_score(y,y_predicted,average = \"weighted\"))\n",
    "print(\"the sensitivity is : \",recall_score(y,y_predicted,average = \"weighted\"))\n",
    "print(\"the f1 is : \",f1_score(y,y_predicted,average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Displaying the decision tree\n",
    "Export the decision tree to \"balance.dot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree_classifier, out_file=\"balance.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Dot file and answer the following questions:\n",
    "1. How many nodes are in the tree?\n",
    "318\n",
    "2. What is the first split\n",
    "\n",
    "0 [label=\"X[3] <= 2.5\\ngini = 0.569\\nsamples = 625\\nvalue = [288, 49, 288]\"] ;\n",
    "\n",
    "1 [label=\"X[1] <= 1.5\\ngini = 0.478\\nsamples = 250\\nvalue = [169, 21, 60]\"] ;\n",
    "\n",
    "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
    "\n",
    "2 [label=\"X[2] <= 2.5\\ngini = 0.566\\nsamples = 50\\nvalue = [14, 7, 29]\"] ;\n",
    "\n",
    "the first split is 0 splitting to 1\n",
    "\n",
    "3. How many leaf nodes are in the tree?  (They will have a lable that just gives a GINI impurity value.)\n",
    "\n",
    "by counting i got 160\n",
    "\n",
    "\n",
    "4. What would you suggest to prevent overfitting?\n",
    "\n",
    "change the max depth or max leaf nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Create a .eps or .png file.\n",
    "\n",
    "To install graphviz, check out https://www.graphviz.org\n",
    "You will probably need to compile and install graphviz, though there may be an executable version you can download.  \n",
    "\n",
    "Once you have the dot file, you can render by command line:\n",
    "\n",
    "```dot -Tps input.dot > output.eps```\n",
    "\n",
    "```dot -Tpng input.dot > output.png```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### *******************I COULD NOT GET THIS TO WORK************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Cross Validate the model.  \n",
    "Do a 5 fold validation and compute accuracy and the F1 score.  Make sure to use a different instance of a decision tree each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies are:  [0.776, 0.768, 0.8, 0.808, 0.752]\n",
      "Cross validation f1 scores  are:  [0.7758477085781434, 0.7993770913770913, 0.8136296296296296, 0.8398455645779073, 0.7586909090909092]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "validation_accuracy = []\n",
    "validation_f1 = []\n",
    "foldAndValidate = KFold(n_splits = 5, shuffle = True, random_state=133)\n",
    "for trainSetIndices, ValidationSetIndices in foldAndValidate.split(x):\n",
    "    cv_train_set = x.iloc[trainSetIndices]\n",
    "    cv_train_target = y.iloc[trainSetIndices]\n",
    "    \n",
    "    \n",
    "    cv_decision_tree = DecisionTreeClassifier()\n",
    "    cv_decision_tree.fit(cv_train_set, cv_train_target)\n",
    "    \n",
    "    cv_xvalidation = x.iloc[ValidationSetIndices]\n",
    "    cv_y_true = y.iloc[ValidationSetIndices]\n",
    "    cv_y_predicted = cv_decision_tree.predict(cv_xvalidation)\n",
    "    \n",
    "    cv_accuracy_score = accuracy_score(cv_y_true, cv_y_predicted)\n",
    "    cv_f1_score = f1_score(cv_y_true, cv_y_predicted,  average=\"weighted\")\n",
    "    validation_accuracy.append(cv_accuracy_score)\n",
    "    validation_f1.append(cv_f1_score)\n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 scores  are: \", validation_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments here\n",
    "a f1 score  of around 80% suggests good results. May be able to classify but it might have some false positives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Generate Test Sets\n",
    "Since this data set has correct answers that are mathematically defined, we can generate test instances.  Create a test DataFrame with 500 instances called in_range_df with random floating point values that range from 0 to 5.\n",
    "\n",
    "Create a second test DataFrame with 500 instances call out_range_df with random floating point values that range from 0 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.99822362 18.26113337 18.1560224  16.86923711  3.61012296 14.75987889\n",
      "  9.43757601 11.81468607 14.18517491  6.2954537 ]\n",
      "[ 1 14  7  7 15  1 10  6  8  6]\n",
      "['R', 'R', 'R', 'R', 'L', 'R', 'L', 'R', 'R', 'R']\n",
      "{'Class': ['R', 'R', 'R', 'R', 'L', 'R', 'L', 'R', 'R', 'R'], 'Left-Product': array([12.99822362, 18.26113337, 18.1560224 , 16.86923711,  3.61012296,\n",
      "       14.75987889,  9.43757601, 11.81468607, 14.18517491,  6.2954537 ]), 'Right-Product': array([ 1, 14,  7,  7, 15,  1, 10,  6,  8,  6])}\n",
      "  Class  Left-Product  Right-Product\n",
      "0     R     12.998224              1\n",
      "1     R     18.261133             14\n",
      "2     R     18.156022              7\n",
      "3     R     16.869237              7\n",
      "4     L      3.610123             15\n",
      "5     R     14.759879              1\n",
      "6     L      9.437576             10\n",
      "7     R     11.814686              6\n",
      "8     R     14.185175              8\n",
      "9     R      6.295454              6\n"
     ]
    }
   ],
   "source": [
    "# This is sample code that shows how to use Numpy's random number generator to create\n",
    "# features with random values and then combine those features into a dictionary\n",
    "# which we can then convert into a Data Frame.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# A function that computes balance\n",
    "def balance(left, right):\n",
    "    if left<right: return \"L\"\n",
    "    if left==right: return \"B\"\n",
    "    return \"R\"\n",
    "\n",
    "# Generate the same sequence each time\n",
    "np.random.seed(20)\n",
    "\n",
    "# create my data values\n",
    "feature1 = np.random.uniform(3, 20, 10)    # 10 values in the range from 3 to 20 (floats)\n",
    "feature2 = np.random.randint(1, 17, 10)    # 10 values in the range from 1 to 17 (ints)\n",
    "\n",
    "\n",
    "target = [balance(left,right) for (left,right) in zip(feature1, feature2)]\n",
    "print(feature1)\n",
    "print(feature2)\n",
    "print(target)\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = target\n",
    "d[\"Left-Product\"] = feature1\n",
    "d[\"Right-Product\"] = feature2\n",
    "\n",
    "print(d)\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "dataframe = pd.DataFrame(data=d)\n",
    "print(dataframe)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Create a data frame in_range_df\n",
    "# with features Class, Left-Weight, Left-Distance, Right-Weight, and Right-Distance\n",
    "# The randomly generate floating point values from 0 to 5 for each feature. \n",
    "np.random.seed(20)\n",
    "\n",
    "feature1 = np.random.uniform(0, 5, 500)\n",
    "feature2 = np.random.uniform(0, 5, 500)\n",
    "feature3 = np.random.uniform(0, 5, 500)\n",
    "feature4 = np.random.uniform(0, 5, 500)\n",
    "\n",
    "target = [balance(left,right) for (left,right) in zip(feature1, feature2)]\n",
    "d = {}\n",
    "d[\"Class\"] = target\n",
    "d[\"Left-Weight\"] = feature1\n",
    "d[\"Right-Weight\"] = feature2\n",
    "d[\"Left-Distance\"] = feature3\n",
    "d[\"Right-Distance\"] = feature4\n",
    "in_range_df = pd.DataFrame(data = d)\n",
    "\n",
    "# Create a data frame out_range_df\n",
    "# with features Class, Left-Weight, Left-Distance, Right-Weight, and Right-Distance\n",
    "# The randomly generate floating point values from 0 to 10 for each feature. \n",
    "\n",
    "feature1 = np.random.uniform(0, 10, 500)\n",
    "feature2 = np.random.uniform(0, 10, 500)\n",
    "feature3 = np.random.uniform(0, 10, 500)\n",
    "feature4 = np.random.uniform(0, 10, 500)\n",
    "\n",
    "target = [balance(left,right) for (left,right) in zip(feature1, feature2)]\n",
    "d = {}\n",
    "d[\"Class\"] = target\n",
    "d[\"Left-Weight\"] = feature1\n",
    "d[\"Right-Weight\"] = feature2\n",
    "d[\"Left-Distance\"] = feature3\n",
    "d[\"Right-Distance\"] = feature4\n",
    "out_range_df = pd.DataFrame(data = d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - Metrics for the Test Sets\n",
    "Give the confusion matrix, accuracy and F1 score for the two test sets using, (_Note:_ You will probably get a warning that the F1 score is ill-defined. Don't worry about it. Because we are generating floating point values, we will almost never generate a test instance that is balanced.)\n",
    "\n",
    "Use the model that you trained in part 4 to compute the predicted value for the Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************in_range_df******************************************\n",
      "[[236   0]\n",
      " [  0 264]]\n",
      "the accuracy is :  1.0\n",
      "the precision is :  1.0\n",
      "the sensitivity is :  1.0\n",
      "the f1 is :  1.0\n",
      "**************************************************************out_range_df******************************************\n",
      "[[261   0]\n",
      " [  0 239]]\n",
      "the accuracy is :  1.0\n",
      "the precision is :  1.0\n",
      "the sensitivity is :  1.0\n",
      "the f1 is :  1.0\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "in_range_df[\"intClass\"] = in_range_df[\"Class\"].map(intClassFn)\n",
    "y = in_range_df[\"intClass\"]\n",
    "x= in_range_df[[\"Left-Weight\",\"Left-Distance\",\"Right-Weight\",\"Right-Distance\"]]\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(x,y)\n",
    "y_predicted = tree_classifier.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "\n",
    "print(\"**************************************************************in_range_df******************************************\")\n",
    "print(matrix)\n",
    "print(\"the accuracy is : \",accuracy_score(y,y_predicted))\n",
    "print(\"the precision is : \",precision_score(y,y_predicted,average = \"weighted\"))\n",
    "print(\"the sensitivity is : \",recall_score(y,y_predicted,average = \"weighted\"))\n",
    "print(\"the f1 is : \",f1_score(y,y_predicted,average = \"weighted\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_range_df[\"intClass\"] = out_range_df[\"Class\"].map(intClassFn)\n",
    "y = out_range_df[\"intClass\"]\n",
    "x= out_range_df[[\"Left-Weight\",\"Left-Distance\",\"Right-Weight\",\"Right-Distance\"]]\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(x,y)\n",
    "y_predicted = tree_classifier.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "\n",
    "print(\"**************************************************************out_range_df******************************************\")\n",
    "print(matrix)\n",
    "print(\"the accuracy is : \",accuracy_score(y,y_predicted))\n",
    "print(\"the precision is : \",precision_score(y,y_predicted,average = \"weighted\"))\n",
    "print(\"the sensitivity is : \",recall_score(y,y_predicted,average = \"weighted\"))\n",
    "print(\"the f1 is : \",f1_score(y,y_predicted,average = \"weighted\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "1. Plot the perfomance of the model as the maximum random value in your test set increases.\n",
    "1. Redefine the balance function so that it returns balanced if the difference between the products is less than 0.5 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
