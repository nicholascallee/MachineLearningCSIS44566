{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9 Neural Nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "To start we are going to examine a classical Perceptron.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  AND  OR  XOR\n",
      "0  1  1    1   1    0\n",
      "1  1  0    0   1    1\n",
      "2  0  1    0   1    1\n",
      "3  0  0    0   0    0\n"
     ]
    }
   ],
   "source": [
    "## Lets start with simple logic functions of two arguments \n",
    "# A with B\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "logic_data = np.array([\n",
    "    [1, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [0, 1, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "# slice it into a dictionary\n",
    "d = {}\n",
    "d['A'] = logic_data[:,0]  #This is the first column\n",
    "d['B'] = logic_data[:,1]  \n",
    "d['AND'] = logic_data[:,2]  \n",
    "d['OR'] = logic_data[:,3]  \n",
    "d['XOR'] = logic_data[:,4]  \n",
    "logic_df = pd.DataFrame(d)\n",
    "\n",
    "print(logic_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Create and train a MLPClassifier on the logic data frame.  Since this is a perceptron, there will be no hidden layer \n",
    "* Use hidden_layer_sizes = () This is an empty tuple of sizes.\n",
    "* Use 'logistic' as the activation.  \n",
    "* Set the maximum number of iterations to 1000 and increase by 1000 until you get convergence.\n",
    "* Use an initial_learning_rate = 0.01  (You can try changing this.)\n",
    "* Use ['A','B'] for X\n",
    "* Use 'AND' for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'initail_learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8d011ce4a6db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     initail_learning_rate = 0.01)\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'initail_learning_rate'"
     ]
    }
   ],
   "source": [
    "\n",
    "# your code here\n",
    "x = logic_df[[\"A\",\"B\"]]\n",
    "y = logic_df['AND']\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    solver='adam', \n",
    "    activation='logistic', \n",
    "    alpha=1e-5, \n",
    "    hidden_layer_sizes=(),\n",
    "    random_state=1,max_iter=1000,\n",
    "    initail_learning_rate = 0.01)\n",
    "mlp.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " using initial_learning_rate = 0.01  gave an error so imma try it without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = logic_df[[\"A\",\"B\"]]\n",
    "y = logic_df['AND']\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    solver='adam', \n",
    "    activation='logistic', \n",
    "    alpha=1e-5, \n",
    "    hidden_layer_sizes=(),\n",
    "    random_state=1,max_iter=1000)\n",
    "mlp.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 \n",
    "Compute a confusion matrix on the logic data frame and see how you did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = mlp.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "Train the model and then compute a confusion matrix using 'OR' for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [2 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(x,y)\n",
    "y = logic_df[\"OR\"]\n",
    "y_predicted = mlp.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "Train the model and then compute a confusion matrix using 'XOR' for y.\n",
    "Print the predicted values of y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [2 0]]\n",
      "*************************************************\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(x,y)\n",
    "y = logic_df[\"XOR\"]\n",
    "y_predicted = mlp.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(matrix)\n",
    "print(\"*************************************************\")\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit this multiple times and remark on the results here:\n",
    "ran the fit 100 times and the result was the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [2 0]]\n",
      "*************************************************\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for n in range(100):\n",
    "    mlp.fit(x,y)\n",
    "y = logic_df[\"XOR\"]\n",
    "y_predicted = mlp.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(matrix)\n",
    "print(\"*************************************************\")\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "Create a new multi-layer-perceptron with a single hidden layer with four nodes.\n",
    "* hidden_layer_sizes = (4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(\n",
    "    solver='adam', \n",
    "    activation='logistic', \n",
    "    alpha=1e-5, \n",
    "    hidden_layer_sizes=(4),\n",
    "    random_state=1,max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "Train the new model and then compute a confusion matrix using 'XOR' for y.\n",
    "Print the predicted values of y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [2 0]]\n",
      "*************************************************\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "mlp2.fit(x,y)\n",
    "y = logic_df[\"XOR\"]\n",
    "y_predicted = mlp.predict(x)\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(matrix)\n",
    "print(\"*************************************************\")\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Balance dataset\n",
    "The data set you will be using in the second part is the same set we used last time the UCI Machine Learning DataSet repository.  \n",
    "http://mlr.cs.umass.edu/ml/datasets/Balance+Scale\n",
    "\n",
    "It is a Balance scale weight & distance database.  You have a left weight and distance and a right weight and distance.  There are three categories:\n",
    "* B is balanced\n",
    "* L is scale tips left\n",
    "* R is scale tips right\n",
    "\n",
    "For the purposses of this assignment, we are going to define balance, we are going to define the categories slightly differently.  We are not going to look for perfect balance, instead we are going to look for a \"close\" balance.  Still compute  left weight*distance and right weight * distance.  If absolute value of the difference is less than 0.5, we will tag it as balanced.  Otherwise if the left product is greater, then we have a tip left, equal is balanced, right greater is tip right.\n",
    "\n",
    "This data set exhaustively gives examples for all 625 posible combinations of weights of 1, 2, 3, 4, 5 with distances of 1, 2, 3, 4, 5.\n",
    "\n",
    "If generating new instances, we should restrict the weight and distance to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given: Get the DataSet and Cross Validate\n",
    "We use a decision tree to give us a base line. We cross validate because the decision tree will overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies are:  [0.76, 0.736, 0.824, 0.776, 0.824]\n",
      "Cross validation f1 scores  are:  [0.77651376146789, 0.7640212201591512, 0.8171428571428571, 0.7894983077528532, 0.8345003830243605]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Get the data setimport pandas as pd\n",
    "balance_df = pd.read_csv(\"balance-scale.csv\")\n",
    "\n",
    "# Add new features\n",
    "balance_df[\"Left-Product\"]=balance_df[\"Left-Weight\"]*balance_df[\"Left-Distance\"]\n",
    "balance_df[\"Right-Product\"]=balance_df[\"Right-Weight\"]*balance_df[\"Right-Distance\"]\n",
    "\n",
    "# Use a decision tree classifier and cross validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "validation_accuracy = []\n",
    "validation_f1 =[]\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_indices, validation_set_indices in fold_and_validate.split(X):\n",
    "    cv_train_set = X.iloc[train_set_indices]\n",
    "    cv_train_target = y.iloc[train_set_indices]\n",
    "    \n",
    "    cv_decision_tree = DecisionTreeClassifier()\n",
    "    cv_decision_tree.fit(cv_train_set, cv_train_target)\n",
    "    \n",
    "    cv_xvalidation = X.iloc[validation_set_indices]\n",
    "    cv_y_true = y.iloc[validation_set_indices]\n",
    "    cv_y_predicted = cv_decision_tree.predict(cv_xvalidation)\n",
    "    \n",
    "    cv_accuracy_score = accuracy_score(cv_y_true, cv_y_predicted)\n",
    "    cv_f1_score = f1_score(cv_y_true, cv_y_predicted,  average=\"weighted\")\n",
    "    validation_accuracy.append(cv_accuracy_score)\n",
    "    validation_f1.append(cv_f1_score)\n",
    "    \n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 scores  are: \", validation_f1)\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given: - Create test sets \n",
    "We will create two test sets\n",
    "```integer_10_test_set```  This set will have integer weights and distances randomly chosen from 1 to 10.  \n",
    "\n",
    "```float_5_test_set```  This set will have floating point weights and distances randomly chosen from 1 to 5.\n",
    "\n",
    "The balance function we will use is not exact balance, but will look for a close balance.  The reason for this is that if we use exact balance we will not get anything in the balanced category for the floating point set.  \n",
    "\n",
    "We print the counts to guarantee that we have enough in the balance category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R    4843\n",
      "L    4831\n",
      "B     326\n",
      "Name: Class, dtype: int64\n",
      "L    4704\n",
      "R    4686\n",
      "B     610\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# A function that computes balance\n",
    "def close_balance(left, right):\n",
    "    if (abs(left-right) < 0.5): return \"B\"\n",
    "    if left<right: return \"R\"\n",
    "    return \"L\"\n",
    "\n",
    "# Generate the same sequence each time\n",
    "np.random.seed(20)\n",
    "\n",
    "# create my data values for integer_10_test_set\n",
    "# create 10000 instances\n",
    "integer_10_leftW = np.random.randint(1, 10, 10000)     \n",
    "integer_10_leftD = np.random.randint(1, 10, 10000)    \n",
    "integer_10_rightW = np.random.randint(1, 10, 10000)    \n",
    "integer_10_rightD = np.random.randint(1, 10, 10000)  \n",
    "integer_10_leftP = integer_10_leftW * integer_10_leftD\n",
    "integer_10_rightP = integer_10_rightW * integer_10_rightD\n",
    "\n",
    "integer_10_target = [close_balance(left,right) for (left,right) in zip(integer_10_leftP, integer_10_rightP)]\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = integer_10_target\n",
    "d[\"Left-Weight\"] = integer_10_leftW\n",
    "d[\"Left-Distance\"] = integer_10_leftD\n",
    "d[\"Right-Weight\"] = integer_10_rightW\n",
    "d[\"Right-Distance\"] = integer_10_rightD\n",
    "d[\"Left-Product\"] = integer_10_leftP\n",
    "d[\"Right-Product\"] = integer_10_rightP\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "integer_10_test_set = pd.DataFrame(data=d)\n",
    "\n",
    "print(integer_10_test_set[\"Class\"].value_counts())\n",
    "\n",
    "\n",
    "# create my data values for float_5_test_set\n",
    "# create 10000 instances\n",
    "float_5_leftW = np.random.uniform(1, 5, 10000)     \n",
    "float_5_leftD = np.random.uniform(1, 5, 10000)    \n",
    "float_5_rightW = np.random.uniform(1, 5, 10000)    \n",
    "float_5_rightD = np.random.uniform(1, 5, 10000)  \n",
    "float_5_leftP = float_5_leftW * float_5_leftD\n",
    "float_5_rightP = float_5_rightW * float_5_rightD\n",
    "\n",
    "float_5_target = [close_balance(left,right) for (left,right) in zip(float_5_leftP, float_5_rightP)]\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = float_5_target\n",
    "d[\"Left-Weight\"] = float_5_leftW\n",
    "d[\"Left-Distance\"] = float_5_leftD\n",
    "d[\"Right-Weight\"] = float_5_rightW\n",
    "d[\"Right-Distance\"] = float_5_rightD\n",
    "d[\"Left-Product\"] = float_5_leftP\n",
    "d[\"Right-Product\"] = float_5_rightP\n",
    "\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "float_5_test_set = pd.DataFrame(data=d)\n",
    "print(float_5_test_set[\"Class\"].value_counts())\n",
    "\n",
    "      \n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given - Train on Balance Data Set and Test our new sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree on the integers from 1 to 10 test set\n",
      "[[   0  200  126]\n",
      " [   0 4702  129]\n",
      " [   0  128 4715]]\n",
      "Accuracy is  0.9417\n",
      "F1 is  0.9261089642329201\n",
      "\n",
      "Evaluating Decision Tree on the floats from 1 to 5 test set\n",
      "[[   0  299  311]\n",
      " [   0 4657   47]\n",
      " [   0   52 4634]]\n",
      "Accuracy is  0.9291\n",
      "F1 is  0.8998710706154994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the classifier\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(X,y)\n",
    "\n",
    "# Test it on our two test sets\n",
    "print(\"Evaluating Decision Tree on the integers from 1 to 10 test set\")\n",
    "X_test_int_10 = integer_10_test_set[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y_true = integer_10_test_set[\"Class\"]\n",
    "\n",
    "y_predicted = tree_classifier.predict(X_test_int_10)\n",
    "matrix = confusion_matrix(y_true, y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"Accuracy is \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "print (\"F1 is \", f1_score(y_true, y_predicted, average=\"weighted\"))\n",
    "\n",
    "print()\n",
    "print(\"Evaluating Decision Tree on the floats from 1 to 5 test set\")\n",
    "X_test_float_5 = float_5_test_set[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y_true = float_5_test_set[\"Class\"]\n",
    "\n",
    "y_predicted = tree_classifier.predict(X_test_float_5)\n",
    "matrix = confusion_matrix(y_true, y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"Accuracy is \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "print (\"F1 is \", f1_score(y_true, y_predicted, average=\"weighted\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Train and Test a Neural Net\n",
    "Use the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n",
    "\n",
    "* Use a single hidden layer of size 20\n",
    "* Use 'logistic' as the activation.  \n",
    "* Set the maximum number of iterations to 1000 and increase by 1000 until you get convergence.\n",
    "* Use an initial_learning_rate = 0.01  (You can try changing this.)\n",
    "\n",
    "\n",
    "Get the performance measures for the two sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Vary size of hidden layer.\n",
    "Use sizes for the hidden layer of 10, 20, 30, 100, 200, 300.\n",
    "Report the confusion matrix and accuracy for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you change the size of the hidden layer how does the performance change:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Vary the number of hidden layers.  \n",
    "Set the sizes for the hidden layers to \n",
    "* ()\n",
    "* (50)\n",
    "* (50, 50)\n",
    "* (50, 50, 50)\n",
    "* (50, 50, 50, 50)\n",
    "\n",
    "Report the confusion matrix and accuracy for each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you change the number of hidden layers how does the performance change:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - Vary solver and activation\n",
    "\n",
    "Set the hidden layers to  (500, 500) and use each of the following combinations\n",
    "* solver='adam', activation='logistic'\n",
    "* solver='adam', activation='relu'\n",
    "* solver='sgd', activation='logistic'\n",
    "* solver='sgd', activation='relu'\n",
    "\n",
    "As well as performance, look at how quickly the network trains.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which combination worked the best:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "Explore the capabilities of neural nets...\n",
    "1. Try different sizes for the hidden layers. We can try decreasing sizes for the hidden layers, increasing sizes, or alternating sizes.  For this data set, which one worked the best?\n",
    "1. Try using other parameter combinations\n",
    "* solver can be 'sgd', 'adam', 'lbfgs'\n",
    "* activation can be 'logistic', 'relu', 'tanh'\n",
    "* batch_size can be an int (Does minibatch with adam or sgd)\n",
    "* learning_rate can be ‘constant’, ‘invscaling’, ‘adaptive’"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
