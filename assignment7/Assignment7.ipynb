{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "The data set you will be using is the same set we used last time the UCI Machine Learning DataSet repository.  \n",
    "http://mlr.cs.umass.edu/ml/datasets/Balance+Scale\n",
    "\n",
    "It is a Balance scale weight & distance database.  You have a left weight and distance and a right weight and distance.  There are three categories:\n",
    "* B is balanced\n",
    "* L is scale tips left\n",
    "* R is scale tips right\n",
    "\n",
    "For the purposses of this assignment, we are going to define balance, we are going to define the categories slightly differently.  We are not going to look for perfect balance, instead we are going to look for a \"close\" balance.  Still compute  left weight*distance and right weight * distance.  If absolute value of the difference is less than 0.5, we will tag it as balanced.  Otherwise if the left product is greater, then we have a tip left, equal is balanced, right greater is tip right.\n",
    "\n",
    "This data set exhaustively gives examples for all 625 posible combinations of weights of 1, 2, 3, 4, 5 with distances of 1, 2, 3, 4, 5.\n",
    "\n",
    "If generating new instances, we should restrict the weight and distance to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given: Get the DataSet and Cross Validate\n",
    "We use a decision tree to give us a base line. We cross validate because the decision tree will overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies are:  [0.76, 0.728, 0.832, 0.776, 0.816]\n",
      "Cross validation f1 scores  are:  [0.7802311612953815, 0.7590341137123745, 0.8248164485981309, 0.7894983077528532, 0.826411009174312]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the data setimport pandas as pd\n",
    "balance_df = pd.read_csv(\"balance-scale.csv\")\n",
    "\n",
    "# Add new features\n",
    "balance_df[\"Left-Product\"]=balance_df[\"Left-Weight\"]*balance_df[\"Left-Distance\"]\n",
    "balance_df[\"Right-Product\"]=balance_df[\"Right-Weight\"]*balance_df[\"Right-Distance\"]\n",
    "\n",
    "# Use a decision tree classifier and cross validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "validation_accuracy = []\n",
    "validation_f1 =[]\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_indices, validation_set_indices in fold_and_validate.split(X):\n",
    "    cv_train_set = X.iloc[train_set_indices]\n",
    "    cv_train_target = y.iloc[train_set_indices]\n",
    "    \n",
    "    cv_decision_tree = DecisionTreeClassifier()\n",
    "    cv_decision_tree.fit(cv_train_set, cv_train_target)\n",
    "    \n",
    "    cv_xvalidation = X.iloc[validation_set_indices]\n",
    "    cv_y_true = y.iloc[validation_set_indices]\n",
    "    cv_y_predicted = cv_decision_tree.predict(cv_xvalidation)\n",
    "    \n",
    "    cv_accuracy_score = accuracy_score(cv_y_true, cv_y_predicted)\n",
    "    cv_f1_score = f1_score(cv_y_true, cv_y_predicted,  average=\"weighted\")\n",
    "    validation_accuracy.append(cv_accuracy_score)\n",
    "    validation_f1.append(cv_f1_score)\n",
    "    \n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 scores  are: \", validation_f1)\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given: - Create test sets \n",
    "We will create two test sets\n",
    "```integer_10_test_set```  This set will have integer weights and distances randomly chosen from 1 to 10.  \n",
    "\n",
    "```float_5_test_set```  This set will have floating point weights and distances randomly chosen from 1 to 5.\n",
    "\n",
    "The balance function we will use is not exact balance, but will look for a close balance.  The reason for this is that if we use exact balance we will not get anything in the balanced category for the floating point set.  \n",
    "\n",
    "We print the counts to guarantee that we have enough in the balance category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R    4843\n",
      "L    4831\n",
      "B     326\n",
      "Name: Class, dtype: int64\n",
      "L    4704\n",
      "R    4686\n",
      "B     610\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# A function that computes balance\n",
    "def close_balance(left, right):\n",
    "    if (abs(left-right) < 0.5): return \"B\"\n",
    "    if left<right: return \"R\"\n",
    "    return \"L\"\n",
    "\n",
    "# Generate the same sequence each time\n",
    "np.random.seed(20)\n",
    "\n",
    "# create my data values for integer_10_test_set\n",
    "# create 10000 instances\n",
    "integer_10_leftW = np.random.randint(1, 10, 10000)     \n",
    "integer_10_leftD = np.random.randint(1, 10, 10000)    \n",
    "integer_10_rightW = np.random.randint(1, 10, 10000)    \n",
    "integer_10_rightD = np.random.randint(1, 10, 10000)  \n",
    "integer_10_leftP = integer_10_leftW * integer_10_leftD\n",
    "integer_10_rightP = integer_10_rightW * integer_10_rightD\n",
    "\n",
    "integer_10_target = [close_balance(left,right) for (left,right) in zip(integer_10_leftP, integer_10_rightP)]\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = integer_10_target\n",
    "d[\"Left-Weight\"] = integer_10_leftW\n",
    "d[\"Left-Distance\"] = integer_10_leftD\n",
    "d[\"Right-Weight\"] = integer_10_rightW\n",
    "d[\"Right-Distance\"] = integer_10_rightD\n",
    "d[\"Left-Product\"] = integer_10_leftP\n",
    "d[\"Right-Product\"] = integer_10_rightP\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "integer_10_test_set = pd.DataFrame(data=d)\n",
    "\n",
    "print(integer_10_test_set[\"Class\"].value_counts())\n",
    "\n",
    "\n",
    "# create my data values for float_5_test_set\n",
    "# create 10000 instances\n",
    "float_5_leftW = np.random.uniform(1, 5, 10000)     \n",
    "float_5_leftD = np.random.uniform(1, 5, 10000)    \n",
    "float_5_rightW = np.random.uniform(1, 5, 10000)    \n",
    "float_5_rightD = np.random.uniform(1, 5, 10000)  \n",
    "float_5_leftP = float_5_leftW * float_5_leftD\n",
    "float_5_rightP = float_5_rightW * float_5_rightD\n",
    "\n",
    "float_5_target = [close_balance(left,right) for (left,right) in zip(float_5_leftP, float_5_rightP)]\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = float_5_target\n",
    "d[\"Left-Weight\"] = float_5_leftW\n",
    "d[\"Left-Distance\"] = float_5_leftD\n",
    "d[\"Right-Weight\"] = float_5_rightW\n",
    "d[\"Right-Distance\"] = float_5_rightD\n",
    "d[\"Left-Product\"] = float_5_leftP\n",
    "d[\"Right-Product\"] = float_5_rightP\n",
    "\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "float_5_test_set = pd.DataFrame(data=d)\n",
    "print(float_5_test_set[\"Class\"].value_counts())\n",
    "\n",
    "      \n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given - Train on Balance Data Set and Test our new sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree on the integers from 1 to 10 test set\n",
      "[[   0  200  126]\n",
      " [   0 4702  129]\n",
      " [   0  128 4715]]\n",
      "Accuracy is  0.9417\n",
      "F1 is  0.9261089642329201\n",
      "\n",
      "Evaluating Decision Tree on the floats from 1 to 5 test set\n",
      "[[   0  299  311]\n",
      " [   0 4657   47]\n",
      " [   0   52 4634]]\n",
      "Accuracy is  0.9291\n",
      "F1 is  0.8998710706154994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the classifier\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(X,y)\n",
    "\n",
    "# Test it on our two test sets\n",
    "print(\"Evaluating Decision Tree on the integers from 1 to 10 test set\")\n",
    "X_test_int_10 = integer_10_test_set[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y_true = integer_10_test_set[\"Class\"]\n",
    "\n",
    "y_predicted = tree_classifier.predict(X_test_int_10)\n",
    "matrix = confusion_matrix(y_true, y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"Accuracy is \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "print (\"F1 is \", f1_score(y_true, y_predicted, average=\"weighted\"))\n",
    "\n",
    "print()\n",
    "print(\"Evaluating Decision Tree on the floats from 1 to 5 test set\")\n",
    "X_test_float_5 = float_5_test_set[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y_true = float_5_test_set[\"Class\"]\n",
    "\n",
    "y_predicted = tree_classifier.predict(X_test_float_5)\n",
    "matrix = confusion_matrix(y_true, y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"Accuracy is \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "print (\"F1 is \", f1_score(y_true, y_predicted, average=\"weighted\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Cross validate linear SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Train and test SVM\n",
    "Train a linear SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Cross validate RBF SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Train and test SVM\n",
    "Train a rbf SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Cross validate polynomial SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Train and test SVM\n",
    "Train a polynomial SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Cross validate sigmoid SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weigh7, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Train and test SVM\n",
    "Train a sigmoid SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose an explanation for the results that you found for the SVM with the different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "1. Use a Stochastic Gradient Descent classifier and compare the performance.\n",
    "1. Use a Random Forrest classifier and compare the performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
