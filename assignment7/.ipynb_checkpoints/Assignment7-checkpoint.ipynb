{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "The data set you will be using is the same set we used last time the UCI Machine Learning DataSet repository.  \n",
    "http://mlr.cs.umass.edu/ml/datasets/Balance+Scale\n",
    "\n",
    "It is a Balance scale weight & distance database.  You have a left weight and distance and a right weight and distance.  There are three categories:\n",
    "* B is balanced\n",
    "* L is scale tips left\n",
    "* R is scale tips right\n",
    "\n",
    "For the purposses of this assignment, we are going to define balance, we are going to define the categories slightly differently.  We are not going to look for perfect balance, instead we are going to look for a \"close\" balance.  Still compute  left weight*distance and right weight * distance.  If absolute value of the difference is less than 0.5, we will tag it as balanced.  Otherwise if the left product is greater, then we have a tip left, equal is balanced, right greater is tip right.\n",
    "\n",
    "This data set exhaustively gives examples for all 625 posible combinations of weights of 1, 2, 3, 4, 5 with distances of 1, 2, 3, 4, 5.\n",
    "\n",
    "If generating new instances, we should restrict the weight and distance to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given: Get the DataSet and Cross Validate\n",
    "We use a decision tree to give us a base line. We cross validate because the decision tree will overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies are:  [0.76, 0.728, 0.824, 0.776, 0.832]\n",
      "Cross validation f1 scores  are:  [0.77651376146789, 0.7592982926012721, 0.8171428571428571, 0.7894983077528532, 0.8393928273561301]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Get the data setimport pandas as pd\n",
    "balance_df = pd.read_csv(\"balance-scale.csv\")\n",
    "\n",
    "# Add new features\n",
    "balance_df[\"Left-Product\"]=balance_df[\"Left-Weight\"]*balance_df[\"Left-Distance\"]\n",
    "balance_df[\"Right-Product\"]=balance_df[\"Right-Weight\"]*balance_df[\"Right-Distance\"]\n",
    "\n",
    "# Use a decision tree classifier and cross validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "validation_accuracy = []\n",
    "validation_f1 =[]\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_indices, validation_set_indices in fold_and_validate.split(X):\n",
    "    cv_train_set = X.iloc[train_set_indices]\n",
    "    cv_train_target = y.iloc[train_set_indices]\n",
    "    \n",
    "    cv_decision_tree = DecisionTreeClassifier()\n",
    "    cv_decision_tree.fit(cv_train_set, cv_train_target)\n",
    "    \n",
    "    cv_xvalidation = X.iloc[validation_set_indices]\n",
    "    cv_y_true = y.iloc[validation_set_indices]\n",
    "    cv_y_predicted = cv_decision_tree.predict(cv_xvalidation)\n",
    "    \n",
    "    cv_accuracy_score = accuracy_score(cv_y_true, cv_y_predicted)\n",
    "    cv_f1_score = f1_score(cv_y_true, cv_y_predicted,  average=\"weighted\")\n",
    "    validation_accuracy.append(cv_accuracy_score)\n",
    "    validation_f1.append(cv_f1_score)\n",
    "    \n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 scores  are: \", validation_f1)\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given: - Create test sets \n",
    "We will create two test sets\n",
    "```integer_10_test_set```  This set will have integer weights and distances randomly chosen from 1 to 10.  \n",
    "\n",
    "```float_5_test_set```  This set will have floating point weights and distances randomly chosen from 1 to 5.\n",
    "\n",
    "The balance function we will use is not exact balance, but will look for a close balance.  The reason for this is that if we use exact balance we will not get anything in the balanced category for the floating point set.  \n",
    "\n",
    "We print the counts to guarantee that we have enough in the balance category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R    4843\n",
      "L    4831\n",
      "B     326\n",
      "Name: Class, dtype: int64\n",
      "L    4704\n",
      "R    4686\n",
      "B     610\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# A function that computes balance\n",
    "def close_balance(left, right):\n",
    "    if (abs(left-right) < 0.5): return \"B\"\n",
    "    if left<right: return \"R\"\n",
    "    return \"L\"\n",
    "\n",
    "# Generate the same sequence each time\n",
    "np.random.seed(20)\n",
    "\n",
    "# create my data values for integer_10_test_set\n",
    "# create 10000 instances\n",
    "integer_10_leftW = np.random.randint(1, 10, 10000)     \n",
    "integer_10_leftD = np.random.randint(1, 10, 10000)    \n",
    "integer_10_rightW = np.random.randint(1, 10, 10000)    \n",
    "integer_10_rightD = np.random.randint(1, 10, 10000)  \n",
    "integer_10_leftP = integer_10_leftW * integer_10_leftD\n",
    "integer_10_rightP = integer_10_rightW * integer_10_rightD\n",
    "\n",
    "integer_10_target = [close_balance(left,right) for (left,right) in zip(integer_10_leftP, integer_10_rightP)]\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = integer_10_target\n",
    "d[\"Left-Weight\"] = integer_10_leftW\n",
    "d[\"Left-Distance\"] = integer_10_leftD\n",
    "d[\"Right-Weight\"] = integer_10_rightW\n",
    "d[\"Right-Distance\"] = integer_10_rightD\n",
    "d[\"Left-Product\"] = integer_10_leftP\n",
    "d[\"Right-Product\"] = integer_10_rightP\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "integer_10_test_set = pd.DataFrame(data=d)\n",
    "\n",
    "print(integer_10_test_set[\"Class\"].value_counts())\n",
    "\n",
    "\n",
    "# create my data values for float_5_test_set\n",
    "# create 10000 instances\n",
    "float_5_leftW = np.random.uniform(1, 5, 10000)     \n",
    "float_5_leftD = np.random.uniform(1, 5, 10000)    \n",
    "float_5_rightW = np.random.uniform(1, 5, 10000)    \n",
    "float_5_rightD = np.random.uniform(1, 5, 10000)  \n",
    "float_5_leftP = float_5_leftW * float_5_leftD\n",
    "float_5_rightP = float_5_rightW * float_5_rightD\n",
    "\n",
    "float_5_target = [close_balance(left,right) for (left,right) in zip(float_5_leftP, float_5_rightP)]\n",
    "\n",
    "# create a dictionary with each feature\n",
    "d = {}\n",
    "d[\"Class\"] = float_5_target\n",
    "d[\"Left-Weight\"] = float_5_leftW\n",
    "d[\"Left-Distance\"] = float_5_leftD\n",
    "d[\"Right-Weight\"] = float_5_rightW\n",
    "d[\"Right-Distance\"] = float_5_rightD\n",
    "d[\"Left-Product\"] = float_5_leftP\n",
    "d[\"Right-Product\"] = float_5_rightP\n",
    "\n",
    "\n",
    "# Create the data frame from the dictionary\n",
    "float_5_test_set = pd.DataFrame(data=d)\n",
    "print(float_5_test_set[\"Class\"].value_counts())\n",
    "\n",
    "      \n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given - Train on Balance Data Set and Test our new sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree on the integers from 1 to 10 test set\n",
      "[[ 256   31   39]\n",
      " [ 691 4017  123]\n",
      " [ 702  113 4028]]\n",
      "Accuracy is  0.8301\n",
      "F1 is  0.8720007886612162\n",
      "\n",
      "Evaluating Decision Tree on the floats from 1 to 5 test set\n",
      "[[ 211  204  195]\n",
      " [ 330 4261  113]\n",
      " [ 336  135 4215]]\n",
      "Accuracy is  0.8687\n",
      "F1 is  0.87713488787475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# Train the classifier\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(X,y)\n",
    "\n",
    "# Test it on our two test sets\n",
    "print(\"Evaluating Decision Tree on the integers from 1 to 10 test set\")\n",
    "X_test_int_10 = integer_10_test_set[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y_true = integer_10_test_set[\"Class\"]\n",
    "\n",
    "y_predicted = tree_classifier.predict(X_test_int_10)\n",
    "matrix = confusion_matrix(y_true, y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"Accuracy is \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "print (\"F1 is \", f1_score(y_true, y_predicted, average=\"weighted\"))\n",
    "\n",
    "print()\n",
    "print(\"Evaluating Decision Tree on the floats from 1 to 5 test set\")\n",
    "X_test_float_5 = float_5_test_set[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y_true = float_5_test_set[\"Class\"]\n",
    "\n",
    "y_predicted = tree_classifier.predict(X_test_float_5)\n",
    "matrix = confusion_matrix(y_true, y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"Accuracy is \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "print (\"F1 is \", f1_score(y_true, y_predicted, average=\"weighted\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Cross validate linear SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies are:  [0.904, 0.888, 0.912, 0.888, 0.896]\n",
      "Cross validation f1 scores  are:  [0.8704297931034483, 0.8471367884451996, 0.8742356902356901, 0.8510804821963627, 0.8627300884955753]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_f1 =[]\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_indices, validation_set_indices in fold_and_validate.split(X):\n",
    "    cv_train_set = X.iloc[train_set_indices]\n",
    "    cv_train_target = y.iloc[train_set_indices]\n",
    "    #print(cv_train_set)\n",
    "    \n",
    "    cv_svc = SVC()\n",
    "    cv_svc.fit(cv_train_set, cv_train_target)\n",
    "    \n",
    "    cv_xvalidation = X.iloc[validation_set_indices]\n",
    "    cv_y_true = y.iloc[validation_set_indices]\n",
    "    cv_y_predicted = cv_svc.predict(cv_xvalidation)\n",
    "    \n",
    "    cv_accuracy_score = accuracy_score(cv_y_true, cv_y_predicted)\n",
    "    cv_f1_score = f1_score(cv_y_true, cv_y_predicted,  average=\"weighted\")\n",
    "    validation_accuracy.append(cv_accuracy_score)\n",
    "    validation_f1.append(cv_f1_score)\n",
    "    \n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 scores  are: \", validation_f1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Train and test SVM\n",
    "Train a linear SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10000, 625]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dbb99264b770>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minteger_10_test_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int 10s: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10000, 625]"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "X = balance_df[[\"Left-Weight\", 'Left-Distance', \"Right-Weight\", \"Right-Distance\"]]\n",
    "y = balance_df['Class']\n",
    "svm_classifier = SVC(kernel=\"linear\")\n",
    "svm_classifier.fit(X,y)\n",
    "\n",
    "\n",
    "y_predicted = svm_classifier.predict(X)\n",
    "\n",
    "y = integer_10_test_set[\"Class\"]\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(\"int 10s: \", matrix)\n",
    "\n",
    "y= float_5_test_set[\"Class\"]\n",
    "matrix = confusion_matrix(y, y_predicted)\n",
    "print(\"float 5s:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Cross validate RBF SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Train and test SVM\n",
    "Train a rbf SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Cross validate polynomial SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weight, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Train and test SVM\n",
    "Train a polynomial SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Cross validate sigmoid SVM\n",
    "Do a 5 fold cross validation on an SVC model using the four features Left-Weigh7, Left-Distance, Right-Weight, and Right-Distance.  Use Class as the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Train and test SVM\n",
    "Train a sigmoid SVC on the balance data set and then get the performance measures for the two test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose an explanation for the results that you found for the SVM with the different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "1. Use a Stochastic Gradient Descent classifier and compare the performance.\n",
    "1. Use a Random Forrest classifier and compare the performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
